{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AkhsjM9w0s2w"
   },
   "source": [
    "# French to English translation system using the **LSTM - Long Short-Term Memory** algorithm\n",
    "## Dataset available on KAgle: https://www.kaggle.com/datasets/devicharith/language-translation-englishfrench?resource=download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "z21oP4S6JeOm"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Importer les bibliothèques\n",
    "import spacy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "wj0i_K1xv51Y"
   },
   "outputs": [],
   "source": [
    "# Charger les modèles de langage français et anglais\n",
    "modele_francais = spacy.load('fr_core_news_sm')\n",
    "modele_anglais = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wPUALOmPxw6e"
   },
   "outputs": [],
   "source": [
    "\n",
    "# load dataa\n",
    "data = pd.read_csv(\"english_french.csv\", delimiter=\",\", header=None, names=[\"English\", \"French\"])\n",
    "\n",
    "# adjust it, remove index\n",
    "data = data[[\"English\", \"French\"]].reset_index(drop=True)\n",
    "\n",
    "\n",
    "data = data.head(5000) # use all dataset for better resultssss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kesYbdgCJmQT",
    "outputId": "a418f0e7-64a2-41ea-bc94-279d917d863c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 2)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "51zQvc3nxLKo",
    "outputId": "ef4e4041-9f93-4949-a558-2a876b8e4f41"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   English                  French\n",
      "0  English words/sentences  French words/sentences\n",
      "1                      Hi.                  Salut!\n",
      "2                     Run!                 Cours !\n",
      "3                     Run!                Courez !\n",
      "4                     Who?                   Qui ?\n",
      "Index(['English', 'French'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(data.head())\n",
    "print(data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "9bMKAgY1JnJ4"
   },
   "outputs": [],
   "source": [
    "# Fusionner et tokeniser la data\n",
    "data[\"tokens_fr\"] = data.iloc[:, 1].apply(modele_francais)\n",
    "data[\"tokens_en\"] = data.iloc[:, 0].apply(modele_anglais)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "r76iYbGqJnMP"
   },
   "outputs": [],
   "source": [
    "# Obtenir le vocabulaire unique pour chaque langue\n",
    "vocabulaire_fr = set([token.text for doc in data[\"tokens_fr\"] for token in doc])\n",
    "vocabulaire_en = set([token.text for doc in data[\"tokens_en\"] for token in doc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "NB-zxQPjJnOk"
   },
   "outputs": [],
   "source": [
    "# Créer des dictionnaires de tokens vers index pour chaque vocabulaire\n",
    "index_fr = {token: i + 1 for i, token in enumerate(vocabulaire_fr)}\n",
    "index_en = {token: i + 1 for i, token in enumerate(vocabulaire_en)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "cjFMRzCJJnQg"
   },
   "outputs": [],
   "source": [
    "# Fonctions pour convertir des séquences de tokens en indices\n",
    "def convertir_tokens_fr(tokens):\n",
    "    return [index_fr.get(token.text, 0) for token in tokens]\n",
    "\n",
    "def convertir_tokens_en(tokens):\n",
    "    return [index_en.get(token.text, 0) for token in tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "TWRx3bUIJ898"
   },
   "outputs": [],
   "source": [
    "# Appliquer la conversion des tokens en indices\n",
    "data[\"indices_fr\"] = data[\"tokens_fr\"].apply(convertir_tokens_fr)\n",
    "data[\"indices_en\"] = data[\"tokens_en\"].apply(convertir_tokens_en)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "cjb5yjd3J9Ak"
   },
   "outputs": [],
   "source": [
    "# Utiliser Keras pour uniformiser la longueur des séquences\n",
    "sequence_fr = tf.keras.preprocessing.sequence.pad_sequences(data[\"indices_fr\"], padding=\"post\")\n",
    "sequence_en = tf.keras.preprocessing.sequence.pad_sequences(data[\"indices_en\"], padding=\"post\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vI5B1jovKngB",
    "outputId": "ae45c767-1a2a-4a6f-9335-56bbafc9d22c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 134ms/step - accuracy: 0.3529 - loss: 5.3561 - val_accuracy: 0.3260 - val_loss: 4.0923\n",
      "Epoch 2/10\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 139ms/step - accuracy: 0.3697 - loss: 3.4502 - val_accuracy: 0.3303 - val_loss: 3.8956\n",
      "Epoch 3/10\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 125ms/step - accuracy: 0.4273 - loss: 3.2240 - val_accuracy: 0.3358 - val_loss: 3.7613\n",
      "Epoch 4/10\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 130ms/step - accuracy: 0.4326 - loss: 3.0464 - val_accuracy: 0.3473 - val_loss: 3.6221\n",
      "Epoch 5/10\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 131ms/step - accuracy: 0.4936 - loss: 2.8663 - val_accuracy: 0.3955 - val_loss: 3.5108\n",
      "Epoch 6/10\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 129ms/step - accuracy: 0.5551 - loss: 2.7125 - val_accuracy: 0.4102 - val_loss: 3.4151\n",
      "Epoch 7/10\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 131ms/step - accuracy: 0.5692 - loss: 2.5917 - val_accuracy: 0.4205 - val_loss: 3.3014\n",
      "Epoch 8/10\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 145ms/step - accuracy: 0.5741 - loss: 2.4761 - val_accuracy: 0.4300 - val_loss: 3.2315\n",
      "Epoch 9/10\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 141ms/step - accuracy: 0.5864 - loss: 2.3845 - val_accuracy: 0.4480 - val_loss: 3.1666\n",
      "Epoch 10/10\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 145ms/step - accuracy: 0.5926 - loss: 2.3038 - val_accuracy: 0.4533 - val_loss: 3.1284\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 46ms/step - accuracy: 0.6194 - loss: 2.1178\n",
      "Précision d'évaluation : 57.29%\n"
     ]
    }
   ],
   "source": [
    "# Taille du vocabulaire\n",
    "taille_vocabulaire_fr = len(index_fr)\n",
    "taille_vocabulaire_en = len(index_en)\n",
    "\n",
    "# Définir le modèle\n",
    "modele_seq2seq = tf.keras.Sequential([\n",
    "    # Couche d'Embedding pour les mots\n",
    "    tf.keras.layers.Embedding(input_dim=taille_vocabulaire_fr + 1, output_dim=128, mask_zero=True),\n",
    "\n",
    "    # Couche LSTM bidirectionnelle\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(128, return_sequences=True)),\n",
    "\n",
    "    # Deuxième couche LSTM bidirectionnelle\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(128, return_sequences=False)),\n",
    "\n",
    "    # Répéter le vecteur pour correspondre aux séquences de sortie\n",
    "    tf.keras.layers.RepeatVector(sequence_en.shape[1]),\n",
    "\n",
    "    # Couche LSTM supplémentaire pour le décodeur\n",
    "    tf.keras.layers.LSTM(64, return_sequences=True),\n",
    "\n",
    "    # Couche de sortie avec Softmax pour la classification des tokens\n",
    "    tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(taille_vocabulaire_en + 1, activation=\"softmax\"))\n",
    "])\n",
    "\n",
    "# Compiler le modèle\n",
    "modele_seq2seq.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "# Entraînement du modèle\n",
    "historique = modele_seq2seq.fit(sequence_fr, sequence_en, epochs=10, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# Évaluation du modèle sur les données d'entraînement\n",
    "evaluation = modele_seq2seq.evaluate(sequence_fr, sequence_en)\n",
    "print(f\"Précision d'évaluation : {evaluation[1] * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 379
    },
    "id": "_KV1Ew_eKniY",
    "outputId": "92ecfdba-17dc-4483-a246-e8731929897f"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)                │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)               │         <span style=\"color: #00af00; text-decoration-color: #00af00\">346,240</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ bidirectional (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)        │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)               │         <span style=\"color: #00af00; text-decoration-color: #00af00\">263,168</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ bidirectional_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)      │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                   │         <span style=\"color: #00af00; text-decoration-color: #00af00\">394,240</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ repeat_vector (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">RepeatVector</span>)         │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ lstm_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                        │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">82,176</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ time_distributed (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)   │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1388</span>)               │          <span style=\"color: #00af00; text-decoration-color: #00af00\">90,220</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)                │ (\u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m128\u001b[0m)               │         \u001b[38;5;34m346,240\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ bidirectional (\u001b[38;5;33mBidirectional\u001b[0m)        │ (\u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m256\u001b[0m)               │         \u001b[38;5;34m263,168\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ bidirectional_1 (\u001b[38;5;33mBidirectional\u001b[0m)      │ (\u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m256\u001b[0m)                   │         \u001b[38;5;34m394,240\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ repeat_vector (\u001b[38;5;33mRepeatVector\u001b[0m)         │ (\u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m256\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ lstm_2 (\u001b[38;5;33mLSTM\u001b[0m)                        │ (\u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m64\u001b[0m)                 │          \u001b[38;5;34m82,176\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ time_distributed (\u001b[38;5;33mTimeDistributed\u001b[0m)   │ (\u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m1388\u001b[0m)               │          \u001b[38;5;34m90,220\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,528,134</span> (13.46 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m3,528,134\u001b[0m (13.46 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,176,044</span> (4.49 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,176,044\u001b[0m (4.49 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,352,090</span> (8.97 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m2,352,090\u001b[0m (8.97 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "modele_seq2seq.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "y_71MZX5274o"
   },
   "outputs": [],
   "source": [
    "#model.save(\"translation_model.h5\")\n",
    "modele_seq2seq.save('translation_model.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Z0uU1Nqxv51c"
   },
   "outputs": [],
   "source": [
    "# Tester une prédiction avec des données\n",
    "def tester_traduction(entree_francais):\n",
    "    # Tokeniser et encoder la phrase d'entrée\n",
    "    tokens = modele_francais(entree_francais)\n",
    "    sequence = convertir_tokens_fr(tokens)\n",
    "    sequence = tf.keras.preprocessing.sequence.pad_sequences([sequence], maxlen=sequence_fr.shape[1], padding=\"post\")\n",
    "\n",
    "    # Générer la prédiction\n",
    "    prediction = modele_seq2seq.predict(sequence)\n",
    "    prediction_indices = np.argmax(prediction[0], axis=-1)\n",
    "\n",
    "    # Décoder la séquence prédite en mots anglais\n",
    "    mots_predits = [list(index_en.keys())[list(index_en.values()).index(i)] for i in prediction_indices if i in index_en.values()]\n",
    "    traduction = \" \".join(mots_predits)\n",
    "\n",
    "    print(f\"Traduction prédite : {traduction}\")\n",
    "\n",
    "# Exemple de test de traduction\n",
    "tester_traduction(\"Bonjour, comment allez-vous ?\")\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
