{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "Zfc9l9G-NTTg"
   },
   "outputs": [],
   "source": [
    "# Installer les bibliothèques nécessaires\n",
    "!pip install tensorflow spacy\n",
    "!python -m spacy download fr_core_news_sm\n",
    "!python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "z21oP4S6JeOm"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Importer les bibliothèques\n",
    "import spacy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Charger les modèles de langage français et anglais\n",
    "modele_francais = spacy.load('fr_core_news_sm')\n",
    "modele_anglais = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ddWueDP3Ji00"
   },
   "outputs": [],
   "source": [
    "# Charger le dataset\n",
    "dataset_url = \"https://www.kaggle.com/datasets/devicharith/language-translation-englishfrench\"\n",
    "data = pd.read_csv(dataset_url, delimiter=\"\\t\", header=None).head(500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kesYbdgCJmQT"
   },
   "outputs": [],
   "source": [
    "doc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "N3gEYo17JnEQ"
   },
   "outputs": [],
   "source": [
    "# Fusionner les phrases pour former le corpus complet en français et en anglais\n",
    "corpus_francais = \" \".join(data.iloc[:, 1])\n",
    "corpus_anglais = \" \".join(data.iloc[:, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9bMKAgY1JnJ4"
   },
   "outputs": [],
   "source": [
    "# Tokeniser les phrases avec spacy\n",
    "data[\"tokens_fr\"] = data.iloc[:, 1].apply(modele_francais)\n",
    "data[\"tokens_en\"] = data.iloc[:, 0].apply(modele_anglais)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "r76iYbGqJnMP"
   },
   "outputs": [],
   "source": [
    "# Obtenir le vocabulaire unique pour chaque langue\n",
    "vocabulaire_fr = set([token.text for doc in data[\"tokens_fr\"] for token in doc])\n",
    "vocabulaire_en = set([token.text for doc in data[\"tokens_en\"] for token in doc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NB-zxQPjJnOk"
   },
   "outputs": [],
   "source": [
    "# Créer des dictionnaires de tokens vers index pour chaque vocabulaire\n",
    "index_fr = {token: i + 1 for i, token in enumerate(vocabulaire_fr)}\n",
    "index_en = {token: i + 1 for i, token in enumerate(vocabulaire_en)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cjFMRzCJJnQg"
   },
   "outputs": [],
   "source": [
    "# Fonctions pour convertir des séquences de tokens en indices\n",
    "def convertir_tokens_fr(tokens):\n",
    "    return [index_fr.get(token.text, 0) for token in tokens]\n",
    "\n",
    "def convertir_tokens_en(tokens):\n",
    "    return [index_en.get(token.text, 0) for token in tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TWRx3bUIJ898"
   },
   "outputs": [],
   "source": [
    "# Appliquer la conversion des tokens en indices\n",
    "data[\"indices_fr\"] = data[\"tokens_fr\"].apply(convertir_tokens_fr)\n",
    "data[\"indices_en\"] = data[\"tokens_en\"].apply(convertir_tokens_en)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cjb5yjd3J9Ak"
   },
   "outputs": [],
   "source": [
    "# Utiliser Keras pour uniformiser la longueur des séquences\n",
    "sequence_fr = tf.keras.preprocessing.sequence.pad_sequences(data[\"indices_fr\"], padding=\"post\")\n",
    "sequence_en = tf.keras.preprocessing.sequence.pad_sequences(data[\"indices_en\"], padding=\"post\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vI5B1jovKngB"
   },
   "outputs": [],
   "source": [
    "# Taille du vocabulaire\n",
    "taille_vocabulaire_fr = len(index_fr)\n",
    "taille_vocabulaire_en = len(index_en)\n",
    "\n",
    "# Définir le modèle\n",
    "modele_seq2seq = tf.keras.Sequential([\n",
    "    # Couche d'Embedding pour les mots\n",
    "    tf.keras.layers.Embedding(input_dim=taille_vocabulaire_fr + 1, output_dim=128, mask_zero=True),\n",
    "\n",
    "    # Couche LSTM bidirectionnelle\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(128, return_sequences=True)),\n",
    "\n",
    "    # Deuxième couche LSTM bidirectionnelle\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(128, return_sequences=False)),\n",
    "\n",
    "    # Répéter le vecteur pour correspondre aux séquences de sortie\n",
    "    tf.keras.layers.RepeatVector(sequence_en.shape[1]),\n",
    "\n",
    "    # Couche LSTM supplémentaire pour le décodeur\n",
    "    tf.keras.layers.LSTM(64, return_sequences=True),\n",
    "\n",
    "    # Couche de sortie avec Softmax pour la classification des tokens\n",
    "    tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(taille_vocabulaire_en + 1, activation=\"softmax\"))\n",
    "])\n",
    "\n",
    "# Compiler le modèle\n",
    "modele_seq2seq.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "# Entraînement du modèle\n",
    "historique = modele_seq2seq.fit(sequence_fr, sequence_en, epochs=10, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# Évaluation du modèle sur les données d'entraînement\n",
    "evaluation = modele_seq2seq.evaluate(sequence_fr, sequence_en)\n",
    "print(f\"Précision d'évaluation : {evaluation[1] * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_KV1Ew_eKniY"
   },
   "outputs": [],
   "source": [
    "modele_seq2seq.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "y_71MZX5274o"
   },
   "outputs": [],
   "source": [
    "#model.save(\"translation_model.h5\")\n",
    "modele_seq2seq.save('translation_model.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tester une prédiction avec des données\n",
    "def tester_traduction(entree_francais):\n",
    "    # Tokeniser et encoder la phrase d'entrée\n",
    "    tokens = modele_francais(entree_francais)\n",
    "    sequence = convertir_tokens_fr(tokens)\n",
    "    sequence = tf.keras.preprocessing.sequence.pad_sequences([sequence], maxlen=sequence_fr.shape[1], padding=\"post\")\n",
    "\n",
    "    # Générer la prédiction\n",
    "    prediction = modele_seq2seq.predict(sequence)\n",
    "    prediction_indices = np.argmax(prediction[0], axis=-1)\n",
    "\n",
    "    # Décoder la séquence prédite en mots anglais\n",
    "    mots_predits = [list(index_en.keys())[list(index_en.values()).index(i)] for i in prediction_indices if i in index_en.values()]\n",
    "    traduction = \" \".join(mots_predits)\n",
    "\n",
    "    print(f\"Traduction prédite : {traduction}\")\n",
    "\n",
    "# Exemple de test de traduction\n",
    "tester_traduction(\"Bonjour, comment allez-vous ?\")\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
